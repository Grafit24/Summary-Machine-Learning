---
tags:
  - ML
  - NLP
  - classic
  - classification
---
Также известна как [[Logistic Regression]] и относится [[Discriminative Models]].
Как и в случае других методов [[Text Classification.canvas|Text Classification]] мы используем general pipeline, который подразумевает
- приведения текста к некоторым фичам $h=(f_1, f_2, ..., f_n)$ (e.g. [[Bag of Words]])
- после этого мы учим веса соответсвующие каждой фичи, для каждого $i$-го класса: $w^{(i)}=(w_1^{(i)}, \dots, w_n^{(i)})$.
- далее мы берём dot product $a_k = w^{(k)} \cdot h + b_k$ для кажого $k$ класса и добавляем баес.
- после этого мы берём результаты предыдущего шага для кажого класса и считаем по ним [[Softmax]].

![[Pasted image 20230912214115.png]]

Т.к. логистическая регрессия дискриминативный метод, то мы учимся разграничивать данные. Обучение регрессии происходит с помощью [[Cross Entropy]].